import pandas as pd
import numpy as np
from numpy.linalg import norm
from dotenv import load_dotenv
import os
from openai import OpenAI
import json
import streamlit as st

# Load environment variables
load_dotenv()

# Initialize OpenAI client with API key
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Load the CSV with embeddings
df = pd.read_csv('embeddings.csv')

# Convert string back to numpy arrays in the 'embedding' column
df['embedding'] = df['embedding'].apply(eval).apply(np.array)

# Load JSON data from file
with open('document.json', 'r', encoding='utf-8') as file:
    document_data = json.load(file)

# Convert JSON data into a dictionary for quick access
document_dict = {}
for doc in document_data:
    for section in doc['sections']:
        key = (doc['filename'], section['title'])
        document_dict[key] = section['content']

# Define a threshold for minimum similarity
SIMILARITY_THRESHOLD = 0.3  # Adjust this value based on experimentation

def get_embedding(text, model="text-embedding-3-small"):
    if not isinstance(text, str) or not text.strip():
        st.warning("Invalid or empty text input detected.")
        return np.zeros(1536)  # Return a zero vector for invalid input
    text = text.replace("\n", " ")  # Normalize newlines
    try:
        response = client.embeddings.create(input=text, model=model)
        response_dict = response.to_dict()  # Convert the response object to a dictionary
        embedding_vector = response_dict['data'][0]['embedding']
        return embedding_vector
    except Exception as e:
        st.error(f"An error occurred: {e}")
        return np.zeros(1536)  # Return a zero vector if there's an error

def safe_divide(a, b):
    return a / b if b != 0 else 0

def get_response(user_query):
    user_embedding = get_embedding(user_query, model='text-embedding-3-small')
    user_embedding_np = np.array(user_embedding)

    # Compute cosine similarity between user query and all document embeddings
    similarities = df['embedding'].apply(lambda x: np.dot(x, user_embedding_np) / safe_divide(norm(x) * norm(user_embedding_np), 1))

    # Find the indices of the top 3 most similar documents
    top_indices = similarities.nlargest(3).index

    # Check if the top similarity score meets the threshold
    if similarities.iloc[top_indices[0]] < SIMILARITY_THRESHOLD:
        # If the highest similarity is below the threshold, return a default response
        return "--", None  # None indicates no references

    # Collect context from the top 3 documents and track references
    context = ""
    references = []  # List to store references
    for index in top_indices:
        filename = df.iloc[index]['filename']
        section_title = df.iloc[index]['section_title']
        content_key = (filename, section_title)
        if content_key in document_dict:
            context += document_dict[content_key] + " \n\n"
            references.append({"filename": filename, "title": section_title})  # Collect reference details

    # Generate response using OpenAI's LLM
    if context.strip():
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Du bist ein Assistent, der Fragen zu Dokumenten detailliert und professionell anhand des untenstehenden Kontextes beantwortet. Sollte die Frage aufgrund des Kontextes nicht beantwortet werden können, antworte bitte mit \"Deine Frage scheint nicht Teil der Wissensdatenbank zu sein. Frage etwas zum Thema wissenschaftliches Arbeiten und Kommunizieren.\""},
                    {"role": "user", "content": f"Kontext: {context}\n\nFrage: {user_query}\nAntwort:"}
                ],
                temperature=0,
                max_tokens=300
            )

            if response.choices:
                message_text = response.choices[0].message.content.strip()
                return message_text, references  # Return both the answer and references
            else:
                return "No response generated by the model.", references
        except Exception as e:
            st.error(f"An error occurred during response generation: {e}")
            return "An error occurred while generating the response.", references
    else:
        return "Not enough content to generate a response.", references

# Streamlit UI
st.image("assets/Unidistance_Logo_couleur_RVB.png", width=200) # Display logo
st.markdown("""
*This is a digital reference tool for a psychology methods course, providing quick access to key information from the official textbook.*
""")
st.markdown("### ✍️ Wissenschaftliches Arbeiten und Kommunizieren")
st.markdown("""
Erhalte KI-gestützte Antworten auf Fragen zum wissenschaftlichen Arbeiten und Kommunizieren – 
basierend auf dem offiziellen [Lehrbuch](https://wissarbkom.bitbucket.io/) der Fakultät für Psychologie der Fernuni/UniDistance Schweiz.
""")

# Usage instructions
st.markdown("#### 🔍 So funktioniert es:")
st.markdown("""
Gib eine konkrete Frage zum wissenschaftlichen Arbeiten in das Textfeld ein – z. B. zur Literaturrecherche, Zitierweise oder zur Gliederung wissenschaftlicher Arbeiten.  
Das System durchsucht das Lehrbuch und liefert dir eine präzise Antwort samt Quellenangabe.  
Wenn die Frage nicht im Buch behandelt wird, erhältst du eine entsprechende Rückmeldung.
""")

# User input for the query
user_query = st.text_input(
    "Gib deine Frage ein:",
    placeholder="z. B. Was sind die Abschnitte in einer wissenschaftlichen Arbeit?"
)

if user_query:
    response, references = get_response(user_query)  # Get response and references
    st.write("### Antwort:")
    st.write(response)
    
    # Display references or an unrelated message if no references
    if references:
        st.write("### Quellenangaben:")
        for ref in references:
            st.write(f"- **Datei**: {ref['filename']} | **Titel**: {ref['title']}")
    else:
        st.write("### Hinweis:")
        st.write("Die Frage scheint nicht im Zusammenhang mit den Inhalten der Wissensdatenbank zu stehen. Frage etwas zum Thema wissenschaftliches Arbeiten und Kommunizieren.")
